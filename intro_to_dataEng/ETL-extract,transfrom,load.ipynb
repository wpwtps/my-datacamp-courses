{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Request"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch the Hackernews post\n",
    "resp = requests.get(\"https://hacker-news.firebaseio.com/v0/item/16222426.json\")\n",
    "\n",
    "# Print the response parsed as JSON\n",
    "print(resp.json())\n",
    "\n",
    "# Assign the score of the test to post_score\n",
    "post_score = resp.json()['score']\n",
    "print(post_score)"
   ]
  },
  {
   "source": [
    "# Ectract\n",
    "คือการรวมไฟล์"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract table to a pandas DataFrame\n",
    "def extract_table_to_pandas(tablename, db_engine):\n",
    "    query = \"SELECT * FROM {}\".format(tablename)\n",
    "    return pd.read_sql(query, db_engine)\n",
    "\n",
    "# Connect to the database using the connection URI\n",
    "#postgresql://[user[:password]@][host][:port][/database]\n",
    "\n",
    "connection_uri = \"postgresql://repl:password@localhost:5432/pagila\" \n",
    "\n",
    "db_engine = sqlalchemy.create_engine(connection_uri)\n",
    "\n",
    "# Extract the film table into a pandas DataFrame\n",
    "extract_table_to_pandas('film', db_engine)\n",
    "\n",
    "# Extract the customer table into a pandas DataFrame\n",
    "extract_table_to_pandas('customer', db_engine)"
   ]
  },
  {
   "source": [
    "โค้ดด้านบนคือประมาณว่าจะอ่านข้อมูลไปสร้างตารางที่มีความสัมพันธ์ตามแบบ pandas \n",
    "ประมาณว่าข้อมูลที่ได้มามันยังมีรูปแบบที่ต่างกันอยู่ พอเราจะรวมไฟล์เราก็ต้องทำให้มันเหมือนกัน \n",
    "\n",
    "ใช้ sqlalchemy เพื่อเชื่อมต่อฐานข้อมูล ให้ไปสั่งในรูปแบบ oop ได้\n",
    "\n",
    "ใช้ read_sql ตัวนี้เพื่ออ่าน/ จัดการฐานข้อมูลด้วย sql \n",
    "\n",
    "ที่เราอ่านเจอมาคือมันจะมี read_sql_table(table_name, db_name) กับ read_sql_query(sql_code, db_name) \n",
    "\n",
    "if we use read_sql instead, we dont have to identify _table or read_sql_query."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the rental rate\n",
    "\n",
    "# Get the rental rate column as a string\n",
    "rental_rate_str = film_df.rental_rate.astype(str)\n",
    "\n",
    "# Split up and expand the column\n",
    "rental_rate_expanded = rental_rate_str.str.split('.', expand=True)\n",
    "\n",
    "# Assign the columns to film_df\n",
    "film_df = film_df.assign(\n",
    "    rental_rate_dollar=rental_rate_expanded[0],\n",
    "    rental_rate_cents=rental_rate_expanded[1],\n",
    ")"
   ]
  },
  {
   "source": [
    "# Join"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use groupBy and mean to aggregate the column\n",
    "ratings_per_film_df = rating_df.groupBy('film_id').mean('rating')\n",
    "\n",
    "# Join the tables using the film_id column\n",
    "film_df_with_ratings = film_df.join(\n",
    "    ratings_per_film_df,\n",
    "    film_df.film_id==ratings_per_film_df.film_id\n",
    ")\n",
    "\n",
    "# Show the 5 first results\n",
    "print(film_df_with_ratings.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the pandas DataFrame to parquet\n",
    "film_pdf.to_parquet(\"films_pdf.parquet\")\n",
    "\n",
    "# Write the PySpark DataFrame to parquet\n",
    "film_sdf.write.parquet(\"films_sdf.parquet\")"
   ]
  },
  {
   "source": [
    "parquet = data storage ชนิดหนึ่งของ hadoop มันจะแปลงข้อมูลให้อยู่ในรูปแบบ column ง่ายต่อการค้นหา"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "\n",
    "# Finish the connection URI\n",
    "connection_uri = \"postgresql://repl:password@localhost:5432/dwh\"\n",
    "db_engine_dwh = sqlalchemy.create_engine(connection_uri)\n",
    "\n",
    "# Transformation step, join with recommendations data\n",
    "#join ต่อกันแบบ \n",
    "myTuple = (\"John\", \"Peter\", \"Vicky\")\n",
    "x = \"#\".join(myTuple)\n",
    "print(x)\n",
    "film_pdf_joined = film_pdf.join(recommendations)\n",
    "\n",
    "# Finish the .to_sql() call to write to store.film\n",
    "#to_sql ใช้บันทึกค่าจาก dataframe ไป sql database\n",
    "film_pdf_joined.to_sql(\"film\", db_engine_dwh, schema=\"store\", if_exists=\"replace\")\n",
    "\n",
    "# Run the query to fetch the data\n",
    "pd.read_sql(\"SELECT film_id, recommended_film_ids FROM store.film\", db_engine_dwh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_to_df(tablename, db_engine):\n",
    "    return pd.read_sql(\"SELECT * FROM {}\".format(tablename), db_engine)\n",
    "def split_columns_transform(df, column, pat, suffixes):\n",
    "    # Converts column into str and splits it on pat...\n",
    "def load_df_into_dwh(film_df, tablename, schema, db_engine):\n",
    "    return pd.to_sql(tablename, db_engine, schema=schema, if_exists=\"replace\")\n",
    "\n",
    "# Define the ETL function\n",
    "def etl():\n",
    "    film_df = extract_film_to_pandas()\n",
    "    film_df = transform_rental_rate(film_df)\n",
    "    load_dataframe_to_film(film_df)\n",
    "\n",
    "# Define the ETL task using PythonOperator\n",
    "etl_task = PythonOperator(task_id='etl_film',\n",
    "                          python_callable=etl,\n",
    "                          dag=dag)\n",
    "\n",
    "# Set the upstream to wait_for_table and sample run etl()\n",
    "etl_task.set_upstream(wait_for_table)\n",
    "etl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}